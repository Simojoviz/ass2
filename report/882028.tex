\documentclass[12pt]{article}

\usepackage{listings}
\usepackage{color}
\usepackage[utf8]{inputenc}
\usepackage{float}

\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

% Custom colors

\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}


% Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm,
morekeywords={self},              % Add keywords here
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=tb,                         % Any extra options here
showstringspaces=false
}}


% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

\author{Simone Jovon 882028}
\title{Assignment 2: Discriminative and Generative Classifiers}

\begin{document}
\maketitle

\section{Task Description}

The goal of the assignment is to write a handwritten digit classifier for the 
\textbf{MNIST database}\footnote{\textit{http://yann.lecun.com/exdb/mnist/}}. 
These are composed of 70000 28x28 pixel gray-scale images 
of handwritten digits divided into 60000 training set and 10000 test set.

We have to train the following classifiers on the dataset:
\begin{enumerate}
    \item SVM  using \textbf{linear}, \textbf{polynomial of degree 2}, 
            and \textbf{RBF} kernels;
    \item Random forests;
    \item Naive Bayes classifier where each pixel is distributed according to a Beta 
          distribution of parameters $\alpha$, $\beta$:
          $$
          d(x,\alpha,\beta)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{(\alpha-1)} (1-x)^{(\beta-1)}
          $$
    \item k-NN.
\end{enumerate}

For SVM and random forests we can use any library we want, but we must implement 
the Naive Bayes and k-NN classifiers.
\end{document}